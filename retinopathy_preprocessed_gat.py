# -*- coding: utf-8 -*-
"""DR_preprocessed_GAT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v-vSyX8hF-2jthXtRxkpLGiWTvmgBHDr
"""

from google.colab import drive
drive.mount('/content/drive')

!mkdir /content/IMAGES
!unzip /content/drive/MyDrive/DR_Preprocessed.zip -d /content/IMAGES

!pip install spektral

import tensorflow as tf
import pandas as pd
from tensorflow  import keras
from tensorflow.keras import layers
from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer
from tensorflow.keras.preprocessing.image import ImageDataGenerator
#from stellargraph.layer import GraphAttention
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Activation, InputLayer, Dense, Dropout, Flatten, Input
from spektral.layers import GATConv
from PIL import Image
import keras.backend as K

root_dir = '/content/IMAGES/DR_Preprocessed'
df = pd.read_csv('/content/DR_preprocessed_labels.csv')
labels = df['label'].values

def preprocess():
    def resize_and_crop(image):
        img = Image.fromarray(image.astype(np.uint8))
        image2 = img.resize((512,512))
        return np.array(image2)
    return resize_and_crop



image_datagen = ImageDataGenerator(preprocessing_function=preprocess(), 
                                   validation_split=0.2)

train_datagen = image_datagen.flow_from_dataframe(dataframe=df, 
                                                  target_size=(512,512),
                                                  directory=root_dir,
                                                  x_col='image',
                                                  y_col='label',
                                                  batch_size=64,
                                                  class_mode='raw',
                                                  subset='training')

val_datagen = image_datagen.flow_from_dataframe(dataframe=df, 
                                                target_size=(512,512),
                                                directory=root_dir,
                                                x_col='image',
                                                y_col='label',
                                                batch_size=64,
                                                class_mode='raw',
                                                subset='validation')

# def feature_extractor(input_shape):
#     model = Sequential()
#     model.add(InputLayer(input_shape=input_shape))
#     model.add(conv_layer(32, pool=True))
#     model.add(conv_layer(64, pool=True))
#     model.add(conv_layer(128, pool=True))
#     model.add(conv_layer(256, pool=True))
#     model.add(conv_layer(512))
#     model.add(Conv2D(1, 1, strides=(1,1), padding='same'))

#     return model


# def conv_layer(filters, kernel_size=3, pool=False):
#     layer = Sequential()
#     layer.add(Conv2D(filters, kernel_size, padding='same'))
#     layer.add(BatchNormalization())
#     layer.add(Activation(activation='relu'))
#     if pool==True:
#         layer.add(MaxPooling2D())
        
#     return layer

def feature_extractor(input_shape):
    x = Input(shape=input_shape)
    x = conv_layer(x, 32, pool=True)
    x = conv_layer(x, 64, pool=True)
    x = conv_layer(x, 128, pool=True)
    x = conv_layer(x, 256, pool=True)
    x = conv_layer(x, 512)
    x = Conv2D(1,1, strides=(1,1), padding='same', activation='relu')(x)

    return x 

def conv_layer(x,filters,kernel_size=3,pool=False):
    x = Conv2D(filters,kernel_size, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation(activation='relu')(x)
    if pool==True:
        x = MaxPooling2D()(x)
    
    return x

def gat_model(input_shape):
    x = feature_extractor(input_shape)
    x_shape = #List of x shape
    print(x)
    x = tf.reshape(x, (x_shape[0], x_shape[1]*x_shape[2], x_shape[3]))
    print(x.shape)
    adj_mat = tf.ones((x_shape[0], x_shape[1], x_shape[1]))
    print(adj_mat.shape)
    x_1 = GATConv(channels=8, 
                   attn_heads=1, 
                   activation='elu')([x, adj_mat])
    
    # x_2 = GATConv(channels=5,
    #               attn_heads=1,
    #               activation='softmax')([x_1, adj_mat])

    
    return x

model = gat_model((512,512,3))
#model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
              #loss = 'sparse_categorical_crossentropy',
              #optimizer=tf.keras.optimizers.Adam(lr=0.002), 
              #metrics=['accuracy'])

"""# Running Test on CNN

"""

def test_model(input_shape):
    model = Sequential()
    model.add(feature_extractor(input_shape))
    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1024, activation='relu'))
    model.add(Dense(5, activation='softmax'))

    return model

model = test_model(input_shape=(512,512,3))
model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
              #loss = 'sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(lr=0.002), 
              metrics=['accuracy'])

history = model.fit(train_datagen, 
                    steps_per_epoch=250, 
                    epochs=30,
                    validation_data=val_datagen,
                    #callbacks=[callback],
                    validation_steps=63)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""# Inference/Checking output over one model"""

base_path = '/content/IMAGES/DR_Preprocessed'
img_list = os.listdir(base_path)
img_path = os.path.join(base_path, img_list[476])
img = Image.open(img_path)
img = img.resize((512,512))
img = np.array(img)
plt.imshow(img)

model = feature_extractor(img.shape)
img = img.reshape((1, 512, 512, 3))
x = model(img)

print(f"X type:{type(x)} \nX shape{x.shape}")

"""# Spektral GAT"""

def gat_model(input_shape):
    x = feature_extractor(input_shape)
    x = tf.reshape(x, (batch_size, x.shape[1]*x.shape[2], x.shape[3]))
    adj_mat = tf.ones((batch_size, x.shape[1], x.shape[1]))
    x_1 = GATConv(channles=8, 
                  attn_heads=1, 
                  activation='elu',
                  kernel_regularizer=l2(l2_reg),
                  attn_kernel_regularizer=l2(l2_reg),
                  bias_regularizer=l2(l2_reg))([x, adj_mat])
    
    x_2 = GATConv(channels=5,
                  attn_heads=1,
                  activation='softmax',
                  kernel_regularizer=l2(l2_reg),
                  attn_kernel_regularizer=l2(l2_reg),
                  bias_regularizer=l2(l2_reg))([x_1, adj_mat]))

def gat_training_loop()

gat = gat_model((512,512,3))
gat.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
              #loss = 'sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(lr=0.002), 
              metrics=['accuracy'])

for batch in train data:
    labels, images
    x = feature_ext(images)
    reshape
    adjacency construction

    GAT CONV


    softmax

    classified op