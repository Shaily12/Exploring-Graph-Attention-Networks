# -*- coding: utf-8 -*-
"""Trying GAT model on OCT images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TtkdVsXD-PrkiE73u3C6o0hVEoTmum5_
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle

!cp /content/kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d paultimothymooney/kermany2018

!unzip /content/kermany2018.zip

!pip install spektral

import tensorflow as tf
import pandas as pd
from tensorflow  import keras
from tensorflow.keras import layers
from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Conv1D, Conv2D, BatchNormalization, MaxPooling2D, Activation, InputLayer, Dense, Dropout, Flatten
from spektral.layers import GATConv, GlobalAttentionPool
from tensorflow.keras.regularizers import l2
from PIL import Image

print(len(os.listdir('/content/OCT2017 /test/CNV')))

image_datagen = ImageDataGenerator(rescale = 1/255.0,
                                   samplewise_center=True,
                                   samplewise_std_normalization=True,
                                   width_shift_range=0.4,
                                   height_shift_range=0.2,
                                   rotation_range=30,
                                   zoom_range=0.1,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   shear_range=30,
                                   #preprocessing_function=preprocess(), 
                                   validation_split=0.2)

train_datagen = image_datagen.flow_from_directory('/content/OCT2017 /train',
                                                  batch_size=32,
                                                  target_size=(450,450),
                                                  classes=['CNV','DME','DRUSEN','NORMAL'],
                                                  #class_mode=None,
                                                  color_mode='grayscale',
                                                  shuffle=True,
                                                  seed=42)

val_datagen = image_datagen.flow_from_directory('/content/OCT2017 /test',
                                                 batch_size=32,
                                                 target_size=(450,450),
                                                 classes=['CNV','DME','DRUSEN','NORMAL'],
                                                 #class_mode=None,
                                                 color_mode='grayscale',
                                                shuffle=True,
                                                seed=42)

BATCH_SIZE = 8

input = Input(shape=(450,450,1),batch_size=BATCH_SIZE)
#model.add(conv_layer(32,pool=True))
x = Conv2D(32, 3, padding='same')(input)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(64,pool=True))
x = Conv2D(64, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(128,pool=True))
x = Conv2D(128, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(256,pool=True))
x = Conv2D(64, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(512))
x = Conv2D(512, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)

x = Conv2D(1, 1, strides=(1,1), padding='same')(x)

x = Flatten()(x)
#x_shape = [x.shape[0],x.shape[1],x.shape[2],x.shape[3]]

# pp = tf.compat.v1.placeholder(tf.float32, shape=[BATCH_SIZE, 32,32,1])
# shape = pp.get_shape().as_list() 
   
# dim = np.prod(shape[1:])   
print(x.shape)
#x = tf.expand_dims(x,2)
x = tf.reshape(x,[BATCH_SIZE,784,1])
adj_mat = tf.ones((BATCH_SIZE,784,784))

print(adj_mat.shape,x.shape)

x_1 = GATConv(channels=5, 
                attn_heads=3, 
                activation='elu',
                kernel_regularizer=l2(5e-4),
                attn_kernel_regularizer=l2(5e-4),
                bias_regularizer=l2(5e-4))([x,adj_mat])

x_2 = GATConv(channels=3,
                attn_heads=2,
                activation='elu',
                kernel_regularizer=l2(5e-4),
                attn_kernel_regularizer=l2(5e-4),
                bias_regularizer=l2(5e-4))([x_1,adj_mat])

x_2 = GlobalAttentionPool(128)(x_2)
output = Dense(4,activation='softmax')(x_2)

model = tf.keras.Model(inputs=input, outputs=output) 
print(model.summary())

model.compile(
              #loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), 
              loss = 'categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(0.0003), 
              metrics=['accuracy'])

history = model.fit(train_datagen, 
                    epochs=30,
                    validation_data=val_datagen)

