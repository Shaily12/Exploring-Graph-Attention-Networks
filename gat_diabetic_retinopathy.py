# -*- coding: utf-8 -*-
"""Trying GAT on DR_Preprocessed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDbjJlRv2lGeC-klDdwk6-yQCjTKqIcC
"""

!pip install -q kaggle
!pip install -q kaggle-cli
!mkdir -p ~/.kaggle
!cp "/content/kaggle.json" ~/.kaggle/
!cat ~/.kaggle/kaggle.json 
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d crowww/a-large-scale-fish-dataset

!unzip /content/a-large-scale-fish-dataset.zip

from google.colab import drive
drive.mount('/content/drive')

!mkdir /content/IMAGES
!unzip /content/drive/MyDrive/DR_Preprocessed.zip -d /content/IMAGES

!pip install spektral

import tensorflow as tf
import pandas as pd
from tensorflow  import keras
from tensorflow.keras import layers
from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Activation, InputLayer, Dense, Dropout, Flatten
from spektral.layers import GATConv, GlobalAttentionPool
from tensorflow.keras.regularizers import l2
from PIL import Image

img = Image.open('/content/NA_Fish_Dataset/Black Sea Sprat/00001.png')
plt.imshow(img)
print(np.asarray(img).shape)

root_dir = '/content/NA_Fish_Dataset/'

train_datagen = image_dataset_from_directory(root_dir,
                                             #label_mode='categorical',
                                             batch_size=8,
                                             image_size=(512,512),
                                             validation_split=0.2,
                                             subset='training',
                                             seed=42
                                             )

val_datagen = image_dataset_from_directory(root_dir,
                                           #label_mode='categorical',
                                           batch_size=8,
                                             image_size=(512,512),
                                             validation_split=0.2,
                                             subset='validation',
                                           seed=42
                                             )

root_dir = '/content/IMAGES/DR_Preprocessed'
df = pd.read_csv('/content/DR_preprocessed_labels.csv')
labels = df['label'].values

# def preprocess():
#     def change_contrast(image, level=125):
#         factor = (259 * (level + 255)) / (255 * (259 - level))
#         def contrast(c):
#             return 128 + factor * (c - 128)
#         return img.point(contrast)

#     def custom_preprocess(image):
#         im = Image.fromarray(image)
#         #im = im.convert('LA')
#         im = change_contrast(im)
#         return np.asarray(im)


image_datagen = ImageDataGenerator(samplewise_center=True,
                                   samplewise_std_normalization=True,
                                   width_shift_range=0.4,
                                   height_shift_range=0.2,
                                   rotation_range=30,
                                   zoom_range=0.1,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   shear_range=30,
                                   #preprocessing_function=preprocess(), 
                                   validation_split=0.2)

train_datagen = image_datagen.flow_from_dataframe(dataframe=df, 
                                                  target_size=(512,512),
                                                  directory=root_dir,
                                                  x_col='image',
                                                  y_col='label',
                                                  batch_size=8,
                                                  class_mode='raw',
                                                  subset='training')

val_datagen = image_datagen.flow_from_dataframe(dataframe=df, 
                                                target_size=(512,512),
                                                directory=root_dir,
                                                x_col='image',
                                                y_col='label',
                                                batch_size=8,
                                                class_mode='raw',
                                                subset='validation')

def feature_extractor(input_shape):
    model = Sequential()
    model.add(InputLayer(input_shape=input_shape))
    model.add(conv_layer(32, pool=True))
    model.add(conv_layer(64, pool=True))
    model.add(conv_layer(128, pool=True))
    model.add(conv_layer(256, pool=True))
    model.add(conv_layer(512))
    model.add(Conv2D(1, 1, strides=(1,1), padding='same'))

    return model

def conv_layer(filters, kernel_size=3, pool=False):
    layer = Sequential()
    layer.add(Conv2D(filters, kernel_size, padding='same'))
    layer.add(BatchNormalization())
    layer.add(Activation(activation='relu'))
    if pool==True:
        layer.add(MaxPooling2D())
        
    return layer

"""# Running Test on CNN

"""

def test_model(input_shape):
    model = Sequential()
    model.add(feature_extractor(input_shape))
    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1024, activation='relu'))
    model.add(Dense(5, activation='softmax'))

    return model

model = test_model(input_shape=(512,512,3))
model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
              #loss = 'sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(lr=0.002), 
              metrics=['accuracy'])

history = model.fit(train_datagen, 
                    steps_per_epoch=250, 
                    epochs=30,
                    validation_data=val_datagen,
                    #callbacks=[callback],
                    validation_steps=63)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""# Inference/Checking output over one model"""

base_path = '/content/IMAGES/DR_Preprocessed'
img_list = os.listdir(base_path)
img_path = os.path.join(base_path, img_list[476])
img = Image.open(img_path)
img = img.resize((512,512))
img = np.array(img)
plt.imshow(img)

model = feature_extractor(img.shape)
img = img.reshape((1, 512, 512, 3))
x = model(img)

print(f"X type:{type(x)} \nX shape{x.shape}")

"""# Spektral GAT"""

def feature_extractor(input_shape):
    x = Input(shape=input_shape)
    x = conv_layer(x, 32, pool=True)
    x = conv_layer(x, 64, pool=True)
    x = conv_layer(x, 128, pool=True)
    x = conv_layer(x, 256, pool=True)
    x = conv_layer(x, 512)
    x = Conv2D(1,1, strides=(1,1), padding='same', activation='relu')(x)

    return x 

def conv_layer(x,filters,kernel_size=3,pool=False):
    x = Conv2D(filters,kernel_size, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation(activation='relu')(x)
    if pool==True:
        x = MaxPooling2D()(x)
    
    return x

def gat_model(input_shape):
    x = feature_extractor(input_shape)
    x = tf.reshape(x, (16, x.shape[1]*x.shape[2], x.shape[3]))
    adj_mat = tf.ones((16, x.shape[1], x.shape[1]))
    x_1 = GATConv(channels=8, 
                  attn_heads=1, 
                  activation='elu',
                  kernel_regularizer=l2(5e-4),
                  attn_kernel_regularizer=l2(5e-4),
                  bias_regularizer=l2(5e-4))([x, adj_mat])
    
    x_2 = GATConv(channels=5,
                  attn_heads=1,
                  activation='softmax',
                  kernel_regularizer=l2(5e-4),
                  attn_kernel_regularizer=l2(5e-4),
                  bias_regularizer=l2(5e-4))([x_1, adj_mat])

    x = GlobalAttentionPool(128)(x) 
    output = Dense(5, activation='softmax')(x) 

    return output

model = tf.keras.Model(inputs=Input(shape=(512,512,3)), outputs=gat_model((512,512,3))) 
print(model.summary())
# gat.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
#               #loss = 'sparse_categorical_crossentropy',
#               optimizer=tf.keras.optimizers.Adam(lr=0.002), 
#               metrics=['accuracy'])

for batch in train data:
    labels, images
    x = feature_ext(images)
    reshape
    adjacency construction

    GAT CONV


    softmax

    classified op

"""# GATConv with model

"""

BATCH_SIZE = 8

input = Input(shape=(512,512, 3),batch_size=BATCH_SIZE)
#model.add(conv_layer(32,pool=True))
x = Conv2D(32, 3, padding='same')(input)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(64,pool=True))
x = Conv2D(64, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(128,pool=True))
x = Conv2D(128, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(256,pool=True))
x = Conv2D(64, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)
x = MaxPooling2D()(x)

#model.add(conv_layer(512))
x = Conv2D(512, 3, padding='same')(x)
x = BatchNormalization()(x)
x = Activation(activation='relu')(x)

x = Conv2D(1, 1, strides=(1,1), padding='same')(x)

#x = Flatten()(x)
#x_shape = [x.shape[0],x.shape[1],x.shape[2],x.shape[3]]

# pp = tf.compat.v1.placeholder(tf.float32, shape=[BATCH_SIZE, 32,32,1])
# shape = pp.get_shape().as_list() 
   
# dim = np.prod(shape[1:])   
      
x = tf.reshape(x,(BATCH_SIZE,1024,1))
adj_mat = tf.ones((BATCH_SIZE,1024,1024))

print(adj_mat.shape,x.shape)

x_1 = GATConv(channels=50, 
                attn_heads=50, 
                activation='elu',
                kernel_regularizer=l2(5e-4),
                attn_kernel_regularizer=l2(5e-4),
                bias_regularizer=l2(5e-4))([x,adj_mat])

x_2 = GATConv(channels=25,
                attn_heads=20,
                activation='elu',
                kernel_regularizer=l2(5e-4),
                attn_kernel_regularizer=l2(5e-4),
                bias_regularizer=l2(5e-4))([x_1,adj_mat])

x_2 = GlobalAttentionPool(128)(x_2)
output = Dense(9,activation='softmax')(x_2)

model = tf.keras.Model(inputs=input, outputs=output) 
print(model.summary())

model = VGG16(include_top=False,
              weights=None,
    input_shape=(512,512,3),
    classes=9,
    classifier_activation="softmax",
)

model

model.compile(
              #loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), 
              loss = 'sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(0.003), 
              metrics=['accuracy'])

history = model.fit(train_datagen, 
                    steps_per_epoch=43, 
                    epochs=30,
                    validation_data=val_datagen,
                    #callbacks=[callback],
                    validation_steps=10)
                    #class_weight=class_weight_dict)



def selu(x, alpha=1.67, lmbda=1.05):
    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)

return lmbda * jnp.where(x>0, x, alpha*jnp.exp(x)-alpha)

def selu(x, alpha=1.667, lmbda=1.05):
    return lmbda * jnp.where(x>0, x, alpha*jnp.exp(x)-alpha)

def relu(x, alpha)

